{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":" NO_TL_best.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"bSUJzQ7x1cL_"},"source":[" **CNN and Data Augmentation - *miscusi* Team**\n"]},{"cell_type":"markdown","metadata":{"id":"aEYkKJUh2Fdl"},"source":["Import libraries"]},{"cell_type":"code","metadata":{"id":"kH1uX6e5Y1yw"},"source":["#Import some useful libraries \n","\n","import os\n","import tensorflow as tf\n","import numpy as np\n","import random\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score #to evaluate the performance of your algorithm\n","from sklearn.metrics import confusion_matrix\n","\n","tfk = tf.keras\n","tfkl = tf.keras.layers"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ArY_syz52K2K"},"source":["Load Images"]},{"cell_type":"code","metadata":{"id":"WmBVjUMYbHL0"},"source":["#We load and unzip the images\n","from google.colab import drive\n","drive.mount('/gdrive')\n","\n","%cd /gdrive/MyDrive/TL\n","!unzip dataset.zip\n","\n","# !unzip '/gdrive/MyDrive/challenge_1/dataset.zip'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nm9M15aLSJlQ"},"source":["Random seed"]},{"cell_type":"code","metadata":{"id":"5mn911D5qoAW"},"source":["# Random seed for reproducibility\n","seed = 42\n","\n","random.seed(seed)\n","os.environ['PYTHONHASHSEED'] = str(seed)\n","np.random.seed(seed)\n","tf.random.set_seed(seed)\n","tf.compat.v1.set_random_seed(seed)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rsVIIYK1bmTM","executionInfo":{"status":"ok","timestamp":1637684804194,"user_tz":-60,"elapsed":1115,"user":{"displayName":"valentina gattinoni","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10084267649157287771"}},"outputId":"139b9fe9-e267-4eea-abae-bfaf5b9ff020"},"source":["# Image data generator + split between TRAINING SET and VALIDATION SET\n","\n","cwd = os.getcwd()\n","dataset_dir = os.path.join(cwd, 'training')\n","\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# Data Augmentation on the TRAINING SET \n","\n","train_data_gen = ImageDataGenerator(rescale=1/255.,\n","                                      rotation_range=30,\n","                                      height_shift_range=50,\n","                                      width_shift_range=50,\n","                                      zoom_range=0.3,\n","                                      horizontal_flip=True,\n","                                      vertical_flip=True, \n","                                      fill_mode='reflect',\n","                                      validation_split=0.2) #set the validation split\n","\n","train_generator = train_data_gen.flow_from_directory(directory=dataset_dir,\n","                                               target_size=(256,256),\n","                                               color_mode='rgb',\n","                                               classes=None, \n","                                               class_mode='categorical',\n","                                               batch_size=8,\n","                                               shuffle=True,\n","                                               seed=seed,\n","                                               subset='training')\n","\n","# Validation Set (to simulate the test set ...) --> NO Data Augmentation\n","\n","validation_data_gen=ImageDataGenerator(rescale=1/255.,\n","                                       validation_split=0.2)\n","\n","validation_generator = validation_data_gen.flow_from_directory(directory=dataset_dir,\n","                                               target_size=(256,256),\n","                                               color_mode='rgb',\n","                                               classes=None, \n","                                               class_mode='categorical',\n","                                               batch_size=8,\n","                                               shuffle=True,\n","                                               seed=seed,\n","                                               subset='validation')                              "],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 14189 images belonging to 14 classes.\n","Found 3539 images belonging to 14 classes.\n"]}]},{"cell_type":"markdown","metadata":{"id":"DlI_r-IZXS-a"},"source":["Construction of the *Convolutional Neural Network*"]},{"cell_type":"code","metadata":{"id":"vBPy8RZokrhC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637684866851,"user_tz":-60,"elapsed":287,"user":{"displayName":"valentina gattinoni","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10084267649157287771"}},"outputId":"1f4e7b22-5189-4c53-cae3-712682f37324"},"source":["# We construct our CNN recursively.\n","# In a for loop we create the single block and then concatenate all the blocks.\n","# The number of filters starts from 8 and doubles at each iteration of the for loop\n","start_f = 8 \n","num_classes = 14\n","# Number of blocks, each one CONV + ReLU + POOLING\n","depth = 7\n","\n","model = tf.keras.Sequential()\n","for i in range(depth):\n","  if i == 0:\n","    input_shape = (256,256,3) \n","  else:\n","    input_shape = [None]\n","\n","# Convolutional layer\n","  model.add(tf.keras.layers.Conv2D(filters=start_f,\n","                                   kernel_size=(3,3),\n","                                   strides=(1,1),\n","                                   padding='same',\n","                                   input_shape=input_shape))\n","  \n","# Activation layer\n","  model.add(tf.keras.layers.ReLU())\n","\n","# Max Pooling 2x2\n","  model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2)))\n","\n","  start_f *= 2\n","\n","#FC layer part: 2 dense layers (512 and 128 neurons respectively) + two dropout layers \n","model.add(tf.keras.layers.Flatten())\n","model.add(tf.keras.layers.Dropout(0.5))\n","model.add(tf.keras.layers.Dense(units=512,\n","                                activation='relu'))\n","model.add(tf.keras.layers.Dropout(0.4))\n","model.add(tf.keras.layers.Dense(units=128,\n","                                activation='relu'))\n","model.add(tf.keras.layers.Dense(units=num_classes, activation='softmax'))\n","\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_1 (Conv2D)           (None, 256, 256, 8)       224       \n","                                                                 \n"," re_lu (ReLU)                (None, 256, 256, 8)       0         \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 128, 128, 8)      0         \n"," )                                                               \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 128, 128, 16)      1168      \n","                                                                 \n"," re_lu_1 (ReLU)              (None, 128, 128, 16)      0         \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 64, 64, 16)       0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 64, 64, 32)        4640      \n","                                                                 \n"," re_lu_2 (ReLU)              (None, 64, 64, 32)        0         \n","                                                                 \n"," max_pooling2d_2 (MaxPooling  (None, 32, 32, 32)       0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_4 (Conv2D)           (None, 32, 32, 64)        18496     \n","                                                                 \n"," re_lu_3 (ReLU)              (None, 32, 32, 64)        0         \n","                                                                 \n"," max_pooling2d_3 (MaxPooling  (None, 16, 16, 64)       0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_5 (Conv2D)           (None, 16, 16, 128)       73856     \n","                                                                 \n"," re_lu_4 (ReLU)              (None, 16, 16, 128)       0         \n","                                                                 \n"," max_pooling2d_4 (MaxPooling  (None, 8, 8, 128)        0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_6 (Conv2D)           (None, 8, 8, 256)         295168    \n","                                                                 \n"," re_lu_5 (ReLU)              (None, 8, 8, 256)         0         \n","                                                                 \n"," max_pooling2d_5 (MaxPooling  (None, 4, 4, 256)        0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_7 (Conv2D)           (None, 4, 4, 512)         1180160   \n","                                                                 \n"," re_lu_6 (ReLU)              (None, 4, 4, 512)         0         \n","                                                                 \n"," max_pooling2d_6 (MaxPooling  (None, 2, 2, 512)        0         \n"," 2D)                                                             \n","                                                                 \n"," flatten (Flatten)           (None, 2048)              0         \n","                                                                 \n"," dropout (Dropout)           (None, 2048)              0         \n","                                                                 \n"," dense_1 (Dense)             (None, 512)               1049088   \n","                                                                 \n"," dropout_1 (Dropout)         (None, 512)               0         \n","                                                                 \n"," dense_2 (Dense)             (None, 128)               65664     \n","                                                                 \n"," dense_3 (Dense)             (None, 14)                1806      \n","                                                                 \n","=================================================================\n","Total params: 2,690,270\n","Trainable params: 2,690,270\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","metadata":{"id":"_vUGvdR2YXUV"},"source":["Network Training"]},{"cell_type":"code","metadata":{"id":"3TAR7rQirZkL"},"source":["#We train the network\n","\n","loss = tf.keras.losses.CategoricalCrossentropy()\n","\n","lr = 1e-4\n","\n","optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n","\n","metrics = ['accuracy']\n","\n","model.compile(optimizer=optimizer,\n","              loss = loss,\n","              metrics=metrics)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DFx0nQjOwVem"},"source":["# Early Stopping\n","callbacks=[]\n","# --------------\n","early_stop = True\n","if early_stop:\n","    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n","    callbacks.append(es_callback)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q7cNNcV4se6Q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637696847562,"user_tz":-60,"elapsed":1841655,"user":{"displayName":"valentina gattinoni","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10084267649157287771"}},"outputId":"63c2054e-623d-4fb8-d0cd-5c0567add4bc"},"source":["#Fitting the model\n","model.fit(x=train_generator,\n","          epochs=100,\n","          validation_data=validation_generator,\n","          callbacks=callbacks)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","1774/1774 [==============================] - 300s 163ms/step - loss: 2.0967 - accuracy: 0.3617 - val_loss: 1.6852 - val_accuracy: 0.4411\n","Epoch 2/100\n","1774/1774 [==============================] - 283s 159ms/step - loss: 1.6351 - accuracy: 0.4684 - val_loss: 1.3791 - val_accuracy: 0.5651\n","Epoch 3/100\n","1774/1774 [==============================] - 282s 159ms/step - loss: 1.3495 - accuracy: 0.5649 - val_loss: 1.3004 - val_accuracy: 0.5691\n","Epoch 4/100\n","1774/1774 [==============================] - 281s 159ms/step - loss: 1.1296 - accuracy: 0.6326 - val_loss: 1.2046 - val_accuracy: 0.6123\n","Epoch 5/100\n","1774/1774 [==============================] - 288s 163ms/step - loss: 0.9697 - accuracy: 0.6831 - val_loss: 0.9335 - val_accuracy: 0.6977\n","Epoch 6/100\n","1774/1774 [==============================] - 286s 161ms/step - loss: 0.8541 - accuracy: 0.7209 - val_loss: 1.0914 - val_accuracy: 0.6437\n","Epoch 7/100\n","1774/1774 [==============================] - 275s 155ms/step - loss: 0.7527 - accuracy: 0.7528 - val_loss: 0.8871 - val_accuracy: 0.7075\n","Epoch 8/100\n","1774/1774 [==============================] - 291s 164ms/step - loss: 0.6795 - accuracy: 0.7774 - val_loss: 0.7623 - val_accuracy: 0.7598\n","Epoch 9/100\n","1774/1774 [==============================] - 275s 155ms/step - loss: 0.6180 - accuracy: 0.7962 - val_loss: 0.9279 - val_accuracy: 0.7324\n","Epoch 10/100\n","1774/1774 [==============================] - 271s 153ms/step - loss: 0.5642 - accuracy: 0.8148 - val_loss: 0.7964 - val_accuracy: 0.7607\n","Epoch 11/100\n","1774/1774 [==============================] - 272s 154ms/step - loss: 0.5191 - accuracy: 0.8325 - val_loss: 0.6470 - val_accuracy: 0.7951\n","Epoch 12/100\n","1774/1774 [==============================] - 271s 153ms/step - loss: 0.4738 - accuracy: 0.8445 - val_loss: 0.8504 - val_accuracy: 0.7429\n","Epoch 13/100\n","1774/1774 [==============================] - 276s 155ms/step - loss: 0.4341 - accuracy: 0.8583 - val_loss: 0.6132 - val_accuracy: 0.8036\n","Epoch 14/100\n","1774/1774 [==============================] - 280s 158ms/step - loss: 0.4088 - accuracy: 0.8650 - val_loss: 0.8247 - val_accuracy: 0.7488\n","Epoch 15/100\n","1774/1774 [==============================] - 279s 157ms/step - loss: 0.3842 - accuracy: 0.8741 - val_loss: 0.5513 - val_accuracy: 0.8302\n","Epoch 16/100\n","1774/1774 [==============================] - 280s 158ms/step - loss: 0.3580 - accuracy: 0.8834 - val_loss: 0.3981 - val_accuracy: 0.8825\n","Epoch 17/100\n","1774/1774 [==============================] - 269s 152ms/step - loss: 0.3383 - accuracy: 0.8891 - val_loss: 0.4871 - val_accuracy: 0.8570\n","Epoch 18/100\n","1774/1774 [==============================] - 270s 152ms/step - loss: 0.3205 - accuracy: 0.8946 - val_loss: 0.3750 - val_accuracy: 0.8895\n","Epoch 19/100\n","1774/1774 [==============================] - 268s 151ms/step - loss: 0.2976 - accuracy: 0.9020 - val_loss: 0.8509 - val_accuracy: 0.7550\n","Epoch 20/100\n","1774/1774 [==============================] - 272s 153ms/step - loss: 0.2857 - accuracy: 0.9060 - val_loss: 0.3911 - val_accuracy: 0.8875\n","Epoch 21/100\n","1774/1774 [==============================] - 268s 151ms/step - loss: 0.2741 - accuracy: 0.9087 - val_loss: 0.5138 - val_accuracy: 0.8663\n","Epoch 22/100\n","1774/1774 [==============================] - 269s 152ms/step - loss: 0.2465 - accuracy: 0.9185 - val_loss: 0.4647 - val_accuracy: 0.8680\n","Epoch 23/100\n","1774/1774 [==============================] - 278s 157ms/step - loss: 0.2473 - accuracy: 0.9201 - val_loss: 0.5589 - val_accuracy: 0.8364\n","Epoch 24/100\n","1774/1774 [==============================] - 279s 157ms/step - loss: 0.2419 - accuracy: 0.9180 - val_loss: 0.5249 - val_accuracy: 0.8548\n","Epoch 25/100\n","1774/1774 [==============================] - 279s 157ms/step - loss: 0.2235 - accuracy: 0.9251 - val_loss: 0.4776 - val_accuracy: 0.8584\n","Epoch 26/100\n","1774/1774 [==============================] - 277s 156ms/step - loss: 0.2200 - accuracy: 0.9288 - val_loss: 0.2837 - val_accuracy: 0.9053\n","Epoch 27/100\n","1774/1774 [==============================] - 277s 156ms/step - loss: 0.2075 - accuracy: 0.9307 - val_loss: 0.4489 - val_accuracy: 0.8743\n","Epoch 28/100\n","1774/1774 [==============================] - 281s 159ms/step - loss: 0.2057 - accuracy: 0.9355 - val_loss: 0.5285 - val_accuracy: 0.8437\n","Epoch 29/100\n","1774/1774 [==============================] - 280s 158ms/step - loss: 0.1986 - accuracy: 0.9357 - val_loss: 0.6266 - val_accuracy: 0.8613\n","Epoch 30/100\n","1774/1774 [==============================] - 278s 157ms/step - loss: 0.1876 - accuracy: 0.9382 - val_loss: 0.3745 - val_accuracy: 0.9070\n","Epoch 31/100\n","1774/1774 [==============================] - 283s 160ms/step - loss: 0.1706 - accuracy: 0.9442 - val_loss: 0.4616 - val_accuracy: 0.8751\n","Epoch 32/100\n","1774/1774 [==============================] - 289s 163ms/step - loss: 0.1716 - accuracy: 0.9431 - val_loss: 0.2326 - val_accuracy: 0.9279\n","Epoch 33/100\n","1774/1774 [==============================] - 286s 161ms/step - loss: 0.1681 - accuracy: 0.9465 - val_loss: 0.1915 - val_accuracy: 0.9376\n","Epoch 34/100\n","1774/1774 [==============================] - 277s 156ms/step - loss: 0.1618 - accuracy: 0.9478 - val_loss: 0.5029 - val_accuracy: 0.8494\n","Epoch 35/100\n","1774/1774 [==============================] - 273s 154ms/step - loss: 0.1497 - accuracy: 0.9512 - val_loss: 0.2673 - val_accuracy: 0.9248\n","Epoch 36/100\n","1774/1774 [==============================] - 273s 154ms/step - loss: 0.1528 - accuracy: 0.9497 - val_loss: 0.5421 - val_accuracy: 0.8757\n","Epoch 37/100\n","1774/1774 [==============================] - 271s 152ms/step - loss: 0.1523 - accuracy: 0.9503 - val_loss: 0.5542 - val_accuracy: 0.8565\n","Epoch 38/100\n","1774/1774 [==============================] - 269s 151ms/step - loss: 0.1432 - accuracy: 0.9552 - val_loss: 0.3933 - val_accuracy: 0.9031\n","Epoch 39/100\n","1774/1774 [==============================] - 268s 151ms/step - loss: 0.1383 - accuracy: 0.9561 - val_loss: 0.4472 - val_accuracy: 0.8988\n","Epoch 40/100\n","1774/1774 [==============================] - 271s 152ms/step - loss: 0.1376 - accuracy: 0.9550 - val_loss: 0.1986 - val_accuracy: 0.9387\n","Epoch 41/100\n","1774/1774 [==============================] - 276s 156ms/step - loss: 0.1379 - accuracy: 0.9564 - val_loss: 0.2841 - val_accuracy: 0.9316\n","Epoch 42/100\n","1774/1774 [==============================] - 278s 157ms/step - loss: 0.1303 - accuracy: 0.9583 - val_loss: 0.3462 - val_accuracy: 0.9053\n","Epoch 43/100\n","1774/1774 [==============================] - 278s 157ms/step - loss: 0.1244 - accuracy: 0.9586 - val_loss: 0.4654 - val_accuracy: 0.8743\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fc63981ea10>"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5_zoMwlxHaH0","executionInfo":{"status":"ok","timestamp":1637696875478,"user_tz":-60,"elapsed":4403,"user":{"displayName":"valentina gattinoni","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10084267649157287771"}},"outputId":"f81b1600-b12d-423b-e103-4cbe0b2b3cb6"},"source":["model.save('SubmissionModel') # saves the model in the current folder "],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: SubmissionModel/assets\n"]}]}]}