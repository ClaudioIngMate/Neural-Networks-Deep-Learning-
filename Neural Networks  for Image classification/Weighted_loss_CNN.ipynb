{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Weighted_loss_CNN.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"bSUJzQ7x1cL_"},"source":[" **CNN and Data Augmentation - *miscusi* Team**\n"]},{"cell_type":"markdown","metadata":{"id":"aEYkKJUh2Fdl"},"source":["Import libraries"]},{"cell_type":"code","metadata":{"id":"kH1uX6e5Y1yw"},"source":["#Import some useful libraries \n","\n","import os\n","import tensorflow as tf\n","import numpy as np\n","import random\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score #to evaluate the performance of your algorithm\n","from sklearn.metrics import confusion_matrix\n","\n","tfk = tf.keras\n","tfkl = tf.keras.layers"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ArY_syz52K2K"},"source":["Load Images"]},{"cell_type":"code","metadata":{"id":"WmBVjUMYbHL0"},"source":["#We load and unzip the images\n","from google.colab import drive\n","drive.mount('/gdrive')\n","\n","%cd /gdrive/MyDrive/challenge1DL\n","!unzip dataset.zip\n","\n","# !unzip '/gdrive/MyDrive/challenge_1/dataset.zip'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5mn911D5qoAW"},"source":["# Random seed for reproducibility\n","seed = 42\n","\n","random.seed(seed)\n","os.environ['PYTHONHASHSEED'] = str(seed)\n","np.random.seed(seed)\n","tf.random.set_seed(seed)\n","tf.compat.v1.set_random_seed(seed)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rsVIIYK1bmTM","outputId":"a661d7ee-ff1c-4d29-f67a-fcdc92060ef6"},"source":["# Image data generator + split between TRAINING SET and VALIDATION SET\n","\n","cwd = os.getcwd()\n","dataset_dir = os.path.join(cwd, 'training')\n","\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# Data Augmentation on the TRAINING SET \n","\n","train_data_gen = ImageDataGenerator(rescale=1/255.,\n","                                      rotation_range=30,\n","                                      height_shift_range=50,\n","                                      width_shift_range=50,\n","                                      zoom_range=0.3,\n","                                      horizontal_flip=True,\n","                                      vertical_flip=True, \n","                                      fill_mode='reflect',\n","                                      validation_split=0.2) #set the validation split\n","\n","train_generator = train_data_gen.flow_from_directory(directory=dataset_dir,\n","                                               target_size=(256,256),\n","                                               color_mode='rgb',\n","                                               classes=None, \n","                                               class_mode='categorical',\n","                                               batch_size=8,\n","                                               shuffle=True,\n","                                               seed=seed,\n","                                               subset='training')\n","\n","# Validation Set (to simulate the test set ...) --> NO Data Augmentation\n","\n","validation_data_gen=ImageDataGenerator(rescale=1/255.,\n","                                       validation_split=0.2)\n","\n","validation_generator = validation_data_gen.flow_from_directory(directory=dataset_dir,\n","                                               target_size=(256,256),\n","                                               color_mode='rgb',\n","                                               classes=None, \n","                                               class_mode='categorical',\n","                                               batch_size=8,\n","                                               shuffle=True,\n","                                               seed=seed,\n","                                               subset='validation')                              "],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 14189 images belonging to 14 classes.\n","Found 3539 images belonging to 14 classes.\n"]}]},{"cell_type":"markdown","metadata":{"id":"DlI_r-IZXS-a"},"source":["Construction of the *Convolutional Neural Network*"]},{"cell_type":"code","metadata":{"id":"vBPy8RZokrhC"},"source":["# We construct our CNN recursively.\n","# In a for loop we create the single block and then concatenate all the blocks.\n","# The number of filters starts from 8 and doubles at each iteration of the for loop\n","start_f = 8 \n","num_classes = 14\n","# Number of blocks, each one CONV + ReLU + POOLING\n","depth = 7\n","\n","model = tf.keras.Sequential()\n","for i in range(depth):\n","  if i == 0:\n","    input_shape = (256,256,3) \n","  else:\n","    input_shape = [None]\n","\n","# Convolutional layer\n","  model.add(tf.keras.layers.Conv2D(filters=start_f,\n","                                   kernel_size=(3,3),\n","                                   strides=(1,1),\n","                                   padding='same',\n","                                   input_shape=input_shape))\n","  \n","# Activation layer\n","  model.add(tf.keras.layers.ReLU())\n","\n","# Max Pooling 2x2\n","  model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2)))\n","\n","  start_f *= 2\n","\n","#FC layer part: 2 dense layers (512 and 128 neurons respectively) + two dropout layers \n","model.add(tf.keras.layers.Flatten())\n","model.add(tf.keras.layers.Dropout(0.5))\n","model.add(tf.keras.layers.Dense(units=512,\n","                                activation='relu'))\n","model.add(tf.keras.layers.Dropout(0.4))\n","model.add(tf.keras.layers.Dense(units=128,\n","                                activation='relu'))\n","model.add(tf.keras.layers.Dense(units=num_classes, activation='softmax'))\n","\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_vUGvdR2YXUV"},"source":["Network Training"]},{"cell_type":"code","metadata":{"id":"oetMJhSmlhPs"},"source":["# A weighted version of categorical_crossentropy.\n","# This allows you to attach the problem of having unbalanced classes.\n","\n","import numpy as np\n","from keras import backend as K\n","def weighted_categorical_crossentropy(weights):\n","    \n","    # weighted version of keras.objectives.categorical_crossentropy\n","    #INPUT:\n","       # weights: numpy array of shape (C,) where C is the number of classes\n","    #USAGE:\n","        #weights = np.array([0.5,2,10]) # Class one at 0.5, class 2 twice the normal weights, class 3 10x.\n","        #loss = weighted_categorical_crossentropy(weights)\n","        #model.compile(loss=loss,optimizer='adam')\n","    \n","    weights = K.variable(weights)\n","        \n","    def loss(y_true, y_pred):\n","        # scale predictions so that the class probas of each sample sum to 1\n","        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n","        # clip to prevent NaN's and Inf's\n","        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n","        # calc\n","        loss = y_true * K.log(y_pred) * weights\n","        loss = -K.sum(loss, -1)\n","        return loss\n","    \n","    return loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CsvkMMkvnFlo"},"source":["weights=np.array([0.2672\t,0.5653\t,0.4528\t,0.2189,\t0.1810\t,0.1510\t,0.2702\t,0.3450\t,0.3687\t,1,\t0.1633,\t0.4599,\t0.3922,\t0.04637])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D8pmLDvBo94x"},"source":["#We train the network\n","\n","#loss = tf.keras.losses.CategoricalCrossentropy()\n","loss=weighted_categorical_crossentropy(weights)\n","\n","lr = 1e-4\n","\n","optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n","\n","metrics = ['accuracy']\n","\n","model.compile(optimizer=optimizer,\n","              loss = loss,\n","              metrics=metrics)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DFx0nQjOwVem"},"source":["# Early Stopping\n","callbacks=[]\n","# --------------\n","early_stop = True\n","if early_stop:\n","    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n","    callbacks.append(es_callback)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q7cNNcV4se6Q"},"source":["#Fitting the model\n","model.fit(x=train_generator,\n","          epochs=100,\n","          validation_data=validation_generator,\n","          callbacks=callbacks)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5_zoMwlxHaH0","outputId":"fe5709f4-9a3d-4ef1-85d5-5987cd9e9b25"},"source":["model.save('SubmissionModel') # saves the model in the current folder "],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: SubmissionModel/assets\n"]}]}]}